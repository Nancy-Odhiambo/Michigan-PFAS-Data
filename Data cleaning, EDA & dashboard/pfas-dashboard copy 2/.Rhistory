weight = 1,
fillOpacity = 0.3,
label = ~NAME
) |>
addCircleMarkers(
radius = ~sqrt(Hazard_Index) * 3,  # circle size proportional to Hazard_Index
fillColor = ~hazard_pal(Hazard_Index),
color = NA,                        # no border
fillOpacity = 0.7,
stroke = FALSE,
label = lapply(hazard_popup$popup, HTML),
labelOptions = labelOptions(
direction = "auto",
textsize = "12px",
opacity = 0.9,
offset = c(0, -5)
)
) |>
addLegend(
"bottomright",
pal = hazard_pal,
values = hazard_sites_full$Hazard_Index,
title = "Hazard Index"
)
# Mean hazard index by type of site and number of sites
# Filter merged_data for Hazard_Index > 1 and remove NA types
hazard_data <- merged_data |>
filter(Hazard_Index > 1, !is.na(type)) |>
distinct(hex_id, type, Hazard_Index)
# Aggregate mean Hazard_Index and count of sites by site type
mean_by_type <- hazard_data |>
group_by(type) |>
summarise(mean_hazard = mean(Hazard_Index, na.rm = TRUE),
n_sites = n(),
.groups = "drop")
# Order types by mean hazard descending and get top 10
top_types <- mean_by_type |>
arrange(desc(mean_hazard)) |>
slice_head(n = 10)
# Prepare plot data with factor levels for ordering
plot_data <- mean_by_type |>
filter(type %in% top_types$type) |>
mutate(type = factor(type, levels = top_types$type))
# Create ggplot object
p <- ggplot(plot_data, aes(x = type, y = mean_hazard, fill = type,
text = paste("Site Type:", type,
"<br>Mean Hazard Index:", round(mean_hazard, 2),
"<br>Number of Sites:", n_sites))) +
geom_col(position = position_dodge(width = 0.7), width = 0.7) +
scale_fill_viridis_d(option = "viridis") +
labs(title = "Mean Hazard Index by Site Type (Hazard_Index > 1)",
x = "Site Type",
y = "Mean Hazard Index",
fill = "Site Type",
caption = "Data source: Michigan PFAS Action Response Team (MPART)",
subtitle = "Numbers above bars indicate number of sites per type") +
theme_minimal() +
theme(legend.position = "right",
axis.text.x = element_text(angle = 45, hjust = 1))
# Convert to interactive Plotly object with hover tooltips
ggplotly(p, tooltip = "text")
# Visualizing the type of site by the composition of 4 main analytes with the hazard index
# Filter merged_data for Hazard_Index > 1, remove NA types, keep only main analytes
hazard_data <- merged_data |>
filter(Hazard_Index > 1, !is.na(type)) |>
distinct(hex_id, type, analyte, analyte_value, Hazard_Index) |>
filter(analyte %in% hazard_analytes)
# Summarize total hazard and analyte sums by type
hazard_summary_by_type <- hazard_data |>
group_by(type, analyte) |>
summarise(sum_analyte = sum(analyte_value, na.rm = TRUE), .groups = "drop") |>
# Total hazard per type
left_join(
hazard_data |>
group_by(type) |>
summarise(
total_hazard = sum(Hazard_Index, na.rm = TRUE),
n_sites = n_distinct(hex_id),
.groups = "drop"
),
by = "type"
) |>
# Pivot analytes to columns
pivot_wider(
names_from = analyte,
values_from = sum_analyte,
values_fill = 0
) |>
arrange(desc(total_hazard))
# Assign a unique ID for reactable
tbl_id <- "hazard_summary_table"
# Create the interactive table
rt <- reactable(
hazard_summary_by_type,
elementId = tbl_id,
searchable = TRUE,
filterable = TRUE,
showPageSizeOptions = TRUE,
defaultPageSize = 10,
highlight = TRUE,
bordered = TRUE,
striped = TRUE
)
# Create download button using JS API
download_btn <- tags$button(
"Download CSV",
onclick = sprintf("Reactable.downloadDataCSV('%s', 'hazard_summary_by_type.csv')", tbl_id),
style = "margin-bottom: 10px;"
)
# Display table with download button
browsable(tagList(download_btn, rt))
# Summarize total hazard index per system type
summary_table <- public_water_max_long |>
distinct(system_type, hex_id, Hazard_Index) |>
group_by(system_type) |>
summarise(
total_hazard = sum(Hazard_Index, na.rm = TRUE),
n_sites = n(),
.groups = "drop"
) |>
arrange(desc(total_hazard))
# Assign a unique ID for reactable
tbl_id <- "system_type_hazard_table"
# Create the interactive table
rt <- reactable(
summary_table,
elementId = tbl_id,
columns = list(
system_type = colDef(name = "System Type"),
total_hazard = colDef(name = "Total Hazard"),
n_sites = colDef(name = "Number of Sites")
),
searchable = TRUE,
filterable = TRUE,
showPageSizeOptions = TRUE,
defaultPageSize = 10,
highlight = TRUE,
bordered = TRUE,
striped = TRUE
)
# Create download button using JS API
download_btn <- tags$button(
"Download CSV",
onclick = sprintf("Reactable.downloadDataCSV('%s', 'total_hazard_system_type.csv')", tbl_id),
style = "margin-bottom: 10px;"
)
# Display table with download button
browsable(tagList(download_btn, rt))
# Plotting Mean analyte concnetration per system_name
# Define main hazard analytes
hazard_analytes <- c("HFPODA", "PFNA", "PFBS", "PFHxS")
# Prepare unique values and recode analytes
unique_values <- public_water_max_long |>
distinct(hex_id, system_name, analyte, analyte_value) |>
mutate(analyte = ifelse(analyte %in% hazard_analytes, analyte, "others"),
system_name = tolower(system_name))
# Aggregate mean analyte value by system name
mean_by_system <- unique_values |>
group_by(system_name, analyte) |>
summarise(mean_value = mean(analyte_value, na.rm = TRUE), .groups = "drop")
# Identify top 10 systems by total mean analyte value
top_systems <- mean_by_system |>
group_by(system_name) |>
summarise(total_mean = sum(mean_value)) |>
ungroup() |>
arrange(desc(total_mean)) |>
slice_head(n = 10)
# Filter for top 10 systems and order factor levels
plot_data <- mean_by_system |>
filter(system_name %in% top_systems$system_name) |>
mutate(system_name = factor(system_name, levels = top_systems$system_name))
# Create ggplot object with interactive tooltip
p_mean <- ggplot(plot_data, aes(x = system_name, y = mean_value, fill = analyte,
text = paste("System:", system_name,
"<br>Analyte:", analyte,
"<br>Mean Value:", round(mean_value, 2)))) +
geom_col(position = position_dodge(width = 0.7), width = 0.7) +  # Dodged bar plot
scale_fill_viridis_d(option = "plasma") +  # Color scale
labs(title = "Mean PFAS Analyte Levels by Top 10 Systems",
x = "System Name", y = "Mean Analyte Value", fill = "Analyte",
caption = "Data source: Michigan PFAS Action Response Team (MPART)") +
theme_minimal() +
theme(legend.position = "right", axis.text.x = element_text(angle = 45, hjust = 1))
# Convert ggplot to interactive Plotly object
ggplotly(p_mean, tooltip = "text")
# Mean hazard index by type of site and number of sites
# Filter merged_data for Hazard_Index > 1 and remove NA types
hazard_data <- merged_data |>
filter(Hazard_Index > 1, !is.na(type)) |>
distinct(hex_id, type, Hazard_Index)
# Aggregate mean Hazard_Index and count of sites by site type
mean_by_type <- hazard_data |>
group_by(type) |>
summarise(mean_hazard = mean(Hazard_Index, na.rm = TRUE),
n_sites = n(),
.groups = "drop")
# Order types by mean hazard descending and get top 10
top_types <- mean_by_type |>
arrange(desc(mean_hazard)) |>
slice_head(n = 10)
# Prepare plot data with factor levels for ordering
plot_data <- mean_by_type |>
filter(type %in% top_types$type) |>
mutate(type = factor(type, levels = top_types$type))
# Create ggplot object
p <- ggplot(plot_data, aes(x = type, y = mean_hazard, fill = type,
text = paste("Site Type:", type,
"<br>Mean Hazard Index:", round(mean_hazard, 2),
"<br>Number of Sites:", n_sites))) +
geom_col(position = position_dodge(width = 0.7), width = 0.7) +
scale_fill_viridis_d(option = "viridis") +
labs(title = "Mean Hazard Index by Site Type (Hazard_Index > 1)",
x = "Site Type",
y = "Mean Hazard Index",
fill = "Site Type",
caption = "Data source: Michigan PFAS Action Response Team (MPART)",
subtitle = "Numbers above bars indicate number of sites per type") +
theme_minimal() +
theme(legend.position = "right",
axis.text.x = element_text(angle = 45, hjust = 1))
# Convert to interactive Plotly object with hover tooltips
ggplotly(p, tooltip = "text")
mi_counties <- st_read("GeoFiles/cb_2018_us_county_500k.shp", quiet = TRUE) |> filter(STATEFP == "26")
hazard_analytes <- c("HFPODA", "PFNA", "PFBS", "PFHxS")
analyte_wide <- public_water_max_long |> filter(analyte %in% hazard_analytes) |>
select(hex_id, analyte, analyte_value) |> pivot_wider(names_from = analyte, values_from = analyte_value, values_fill = 0)
hazard_sites_full <- public_water_max_long |> filter(Hazard_Index > 1) |>
distinct(hex_id, system_name, system_type, Hazard_Index, longitude, latitude) |> rename(type = system_type) |>
left_join(analyte_wide, by = "hex_id") |> st_as_sf(coords = c("longitude","latitude"), crs = 4326)
hazard_pal <- colorNumeric(palette = "magma", domain = hazard_sites_full$Hazard_Index)
hazard_popup <- hazard_sites_full |> mutate(popup = paste0(
"System Name: ", system_name, "",
"Type: ", type, "",
"Hazard Index: ", round(Hazard_Index,2), "",
"HFPODA: ", round(HFPODA,2), "",
"PFNA: ", round(PFNA,2), "",
"PFBS: ", round(PFBS,2), "",
"PFHxS: ", round(PFHxS,2)
))
bounds <- st_bbox(hazard_sites_full)
leaflet(hazard_sites_full) |>
addProviderTiles(providers$CartoDB.Positron) |>
addPolygons(data = mi_counties, fillColor="grey", color="black", weight=1, fillOpacity=0.3, label=~NAME) |>
addCircleMarkers(radius = ~sqrt(Hazard_Index)*3, fillColor = ~hazard_pal(Hazard_Index), color=NA, fillOpacity=0.7, stroke=FALSE,
label = lapply(hazard_popup$popup, HTML),
labelOptions = labelOptions(direction="auto", textsize="12px", opacity=0.9, offset=c(0,-5))) |>
addLegend("bottomright", pal = hazard_pal, values = hazard_sites_full$Hazard_Index, title="Hazard Index") |>
fitBounds(bounds$xmin, bounds$ymin, bounds$xmax, bounds$ymax)
#| include: false
set.seed(1994)
# Loading necessary packages
library(tidyverse)
library(naniar)
library(janitor)
library(sf)
library(gt)
library(skimr)
library(tidycensus)
library(maps)
library(patchwork)
library(ggrepel)
library(ggthemes)
library(scales)
library(reshape2)
library(ggcorrplot)
library(flextable)
library(dplyr)
library(tidyr)
library(plotly)
library(leaflet)
library(reactable)
library(reactablefmtr)
library(htmltools)
# Function for creating data dictionary
data_dictionary <- function(myData, descripts) {
tibble(Variable = colnames(myData),
Type = map_chr(myData, .f = function(x){typeof(x)[1]}),
Description = descripts) |>
gt()
}
#| eval: true
#| include: false
# Create function to add geoid variable given longitude and latitude for county-level data
add_geoid <- function(my_data) {
# Create sf object to help add geoid column
my_data_sf <- my_data |>
st_as_sf(coords = c("longitude", "latitude"))
# Set coordinate reference system (CRS) to match counties data
counties <- st_read("GeoFiles//cb_2018_us_county_500k.shp")
st_crs(my_data_sf) <- st_crs(counties)
ret_data <- my_data_sf |>
st_join(counties) |>
mutate(longitude = st_coordinates(geometry)[, 1],
latitude = st_coordinates(geometry)[, 2]) |>
st_drop_geometry() |>
as_tibble() |>
dplyr::select(GEOID, longitude, latitude) |>
dplyr::rename(geoid = GEOID) |>
distinct() |>
right_join(my_data)
return(ret_data)
}
#| eval: true
#| include: false
# Importing data on PFAS levels in surface water in Michigan
analyte_info <- read_csv("PFAS_Surface_Water_Sampling.csv") |>
dplyr::select(-c(X:Latitude, GlobalID, OBJECTID,
ends_with("Flag")))
surface_water <- read_csv("PFAS_Surface_Water_Sampling.csv") |>
clean_names() |>
dplyr::select(-ends_with("_flag")) |>
dplyr::select(-c(cas307244_pf_hx_a:cas919005144_adona_rl)) |>
bind_cols(analyte_info)
# Importing data on surface water data dictionary
surface_water_dictionary <- read_csv("surface_water_data_dictionary.csv")
# Creating long version of surface water data
surface_water_long <- surface_water |>
dplyr::rename(object_id = objectid) |>
dplyr::select(longitude, latitude, object_id, everything(),
-c(x:y), -ends_with("Flag"), -global_id) |>
pivot_longer(cols = colnames(analyte_info),
names_to = "analyte",
values_to = "analyte_value") |>
dplyr::select(-matrix, -unit, -object_id) |>
add_geoid()
# Saving to external CSV
write_csv(surface_water_long, file = "pfas_surface_water_long.csv")
#| eval: true
#| include: false
# Importing shape file data for public water supply PFAS levels data
public_water_shape <- st_read("Public_Water_Supply_Sampling_Hexbins_and_Results/Public_Water_Supply_Sampling_Hexbins.shp") |>
mutate(centroid = st_centroid(geometry),
longitude = st_coordinates(centroid)[, 1],
latitude = st_coordinates(centroid)[, 2]) |>
dplyr::select(HexID, longitude, latitude) |>
st_drop_geometry() |>
as_tibble()
# Importing data on public water supply PFAS levels
public_water <- read_csv("Public_Water_Supply_Sampling_Hexbins_and_Results.csv")
# Adding geoid, longitude, and latitude information to public water data
# and cleaning variable names
public_water_wide <- public_water |>
left_join(public_water_shape, by = "HexID") |>
dplyr::select(-ends_with(c("Result", "Flags"))) |>
clean_names() |>
dplyr::rename(object_id = objectid) |>
dplyr::select(object_id:sys_loc_code, longitude, latitude, everything()) |>
bind_cols(dplyr::select(public_water, ends_with("Result"))) |>
add_geoid()
# Pivoting public water data from wide to long format
public_water_long <- public_water_wide |>
pivot_longer(cols = c(ends_with(c("Result"))),
names_to = "analyte",
values_to = "analyte_value") |>
mutate(analyte = gsub(analyte, pattern = "Result", replacement = "")) |>
dplyr::select(-c(hex_id,
wssn, loc_name:sys_loc_code,
phase_code:task_type,
treatment_status:sys_sample_code,
lab_number:lab_sdg,
object_id, position_source,
analytical_method,
sampling_results_count)) |>
mutate(system_type = fct_recode(system_type,
"Non-Community Water Supply (Adult Foster Care Provider)" = "ADFSTC",
"Non-Community Water Supply (Children's Camp)" = "CHLCMP",
"Non-Community Water Supply (Child Care Provider)" = "DAYCARE",
"Non-Community Water Supply (Industry)" = "INDUS",
"Non-Community Water Supply (Medical Care Provider)" = "MEDCAR",
"Non-Community Water Supply (Hotel or Motel)" = "MOTEL",
"Community Water Supply (for example Municipal Supply, Apartment, Nursing Home, Prison, etc.)" = "MUN",
"Office Building" = "OFFICE",
"Park" = "PARK",
"Residential" = "RESD",
"School" = "SCH",
"Tribal Lands" = "TRB"))
# Saving to external CSV
write_csv(public_water_long, file = "pfas_public_water_long.csv")
#| eval: true
#| include: false
pfas_site_path <- "pfas_sites.csv"
if(file.exists(pfas_site_path) == FALSE) {
# Importing data on identified sites from https://www.michigan.gov/pfasresponse
# Downloaded on 02/25/2025
pfas_sites <- read_csv("Michigan_PFAS_Sites.csv") |>
janitor::clean_names() |>
dplyr::select(facility:site_type, location:military, facility_date, site_background:anticipated_activities, -tier, -site_type) |>
add_geoid()
# Saving cleaned data
write_csv(pfas_sites, file = pfas_site_path)
} else {
# Importing
pfas_sites <- read_csv(pfas_site_path)
}
# Drop flag columns, replace NA in PFAS Result columns with 0, and ensure numeric
public_water_wide <- public_water_wide |>
select(-ends_with("Flags")) |>
mutate(across(ends_with("Result"), ~replace_na(as.numeric(.x), 0)))
# Calculating the hazard index
public_water_wide <- public_water_wide |>
mutate(Hazard_Index = (HFPODAResult / 10) +
(PFNAResult / 10) +
(PFBSResult / 2000) +
(PFHxSResult / 10))
# Displaying the high index areas with the highest analyte contributor in a table
high_hazard <- public_water_wide |>
filter(Hazard_Index > 1) |>
select(hex_id, Hazard_Index, HFPODAResult, PFNAResult, PFBSResult, PFHxSResult) |>
arrange(desc(Hazard_Index)) |>
flextable() |>
set_caption("Public Water Locations with Hazard Index > 1") |>
autofit()
# Extracting the maximum hazard per hex ID
public_water_max <- public_water_wide |>
group_by(hex_id) |>
slice_max(order_by = Hazard_Index, n = 1, with_ties = FALSE) |>
ungroup()
# Changing the wide format to long format
public_water_max_long <- public_water_max |>
pivot_longer(cols = ends_with("Result"),
names_to = "analyte",
values_to = "analyte_value") |>
mutate(analyte = gsub("Result$", "", analyte))
merged_data <- public_water_max_long |>
left_join(
pfas_sites |> mutate(geoid = as.character(geoid)),
by = "geoid",
relationship = "many-to-many"
)
mi_counties <- st_read("GeoFiles/cb_2018_us_county_500k.shp", quiet = TRUE) |> filter(STATEFP == "26")
hazard_analytes <- c("HFPODA", "PFNA", "PFBS", "PFHxS")
analyte_wide <- public_water_max_long |> filter(analyte %in% hazard_analytes) |>
select(hex_id, analyte, analyte_value) |> pivot_wider(names_from = analyte, values_from = analyte_value, values_fill = 0)
hazard_sites_full <- public_water_max_long |> filter(Hazard_Index > 1) |>
distinct(hex_id, system_name, system_type, Hazard_Index, longitude, latitude) |> rename(type = system_type) |>
left_join(analyte_wide, by = "hex_id") |> st_as_sf(coords = c("longitude","latitude"), crs = 4326)
hazard_pal <- colorNumeric(palette = "magma", domain = hazard_sites_full$Hazard_Index)
hazard_popup <- hazard_sites_full |> mutate(popup = paste0(
"System Name: ", system_name, "",
"Type: ", type, "",
"Hazard Index: ", round(Hazard_Index,2), "",
"HFPODA: ", round(HFPODA,2), "",
"PFNA: ", round(PFNA,2), "",
"PFBS: ", round(PFBS,2), "",
"PFHxS: ", round(PFHxS,2)
))
bounds <- st_bbox(hazard_sites_full)
leaflet(hazard_sites_full) |>
addProviderTiles(providers$CartoDB.Positron) |>
addPolygons(data = mi_counties, fillColor="grey", color="black", weight=1, fillOpacity=0.3, label=~NAME) |>
addCircleMarkers(radius = ~sqrt(Hazard_Index)*3, fillColor = ~hazard_pal(Hazard_Index), color=NA, fillOpacity=0.7, stroke=FALSE,
label = lapply(hazard_popup$popup, HTML),
labelOptions = labelOptions(direction="auto", textsize="12px", opacity=0.9, offset=c(0,-5))) |>
addLegend("bottomright", pal = hazard_pal, values = hazard_sites_full$Hazard_Index, title="Hazard Index") |>
fitBounds(bounds$xmin, bounds$ymin, bounds$xmax, bounds$ymax)
county_hazard <- public_water_max |> filter(Hazard_Index > 1) |> distinct(hex_id, Hazard_Index, geoid) |>
group_by(geoid) |> summarise(total_hazard = sum(Hazard_Index, na.rm=TRUE)) |> ungroup() |>
left_join(st_read("GeoFiles/cb_2018_us_county_500k.shp", quiet=TRUE) |> st_drop_geometry() |> select(GEOID, NAME, STATEFP), by=c("geoid"="GEOID")) |>
filter(!is.na(NAME))
p <- ggplot(county_hazard, aes(x=reorder(NAME,total_hazard), y=total_hazard, fill=total_hazard)) +
geom_col() + coord_flip() + labs(title="Public Water Locations with Hazard Index > 1 by County", x="County", y="Total Hazard Index", caption="Data source: MPART") +
scale_fill_viridis_c(option="viridis") + theme_minimal()
ggplotly(p)
unique_values <- public_water_max_long |> distinct(hex_id, system_name, analyte, analyte_value) |>
mutate(analyte = ifelse(analyte %in% hazard_analytes, analyte, "others"), system_name = tolower(system_name))
mean_by_system <- unique_values |> group_by(system_name, analyte) |> summarise(mean_value = mean(analyte_value, na.rm=TRUE), .groups="drop")
top_systems <- mean_by_system |> group_by(system_name) |> summarise(total_mean=sum(mean_value)) |> ungroup() |> arrange(desc(total_mean)) |> slice_head(n=10)
plot_data <- mean_by_system |> filter(system_name %in% top_systems$system_name) |> mutate(system_name=factor(system_name, levels=top_systems$system_name))
p_mean <- ggplot(plot_data, aes(x=system_name, y=mean_value, fill=analyte, text=paste("System:", system_name,"Analyte:", analyte,"Mean Value:", round(mean_value,2)))) +
geom_col(position=position_dodge(width=0.7), width=0.7) + scale_fill_viridis_d(option="plasma") +
labs(title="Mean PFAS Analyte Levels by Top 10 Systems", x="System Name", y="Mean Analyte Value", fill="Analyte", caption="Data source: MPART") +
theme_minimal() + theme(legend.position="right", axis.text.x=element_text(angle=45,hjust=1))
ggplotly(p_mean, tooltip="text")
# Changing the system_type values to be more descriptive
public_water_max_long <- public_water_max_long |>
mutate(system_type = recode(system_type,
"ADFSTC" = "Non-Community Water Supply (Adult Foster Care Provider)",
"CHLCMP" = "Non-Community Water Supply (Children's Camp)",
"DAYCARE" = "Non-Community Water Supply (Child Care Provider)",
"INDUS" = "Non-Community Water Supply (Industry)",
"MEDCAR" = "Non-Community Water Supply (Medical Care Provider)",
"MOTEL" = "Non-Community Water Supply (Hotel or Motel)",
"MUN" = "Community Water Supply (for example Municipal Supply, Apartment, Nursing Home, Prison, etc.)",
"OFFICE" = "Office Building",
"PARK" = "Park",
"RESD" = "Residential",
"SCH" = "School",
"TRB" = "Tribal Lands"
))
hazard_data <- merged_data |> filter(Hazard_Index>1, !is.na(type)) |> distinct(hex_id, type, Hazard_Index)
mean_by_type <- hazard_data |> group_by(type) |> summarise(mean_hazard=mean(Hazard_Index,na.rm=TRUE), n_sites=n(), .groups="drop")
top_types <- mean_by_type |> arrange(desc(mean_hazard)) |> slice_head(n=10)
plot_data <- mean_by_type |> filter(type %in% top_types$type) |> mutate(type=factor(type, levels=top_types$type))
p <- ggplot(plot_data, aes(x=type, y=mean_hazard, fill=type, text=paste("Site Type:", type,"Mean Hazard Index:", round(mean_hazard,2),"Number of Sites:", n_sites))) +
geom_col(position=position_dodge(width=0.7), width=0.7) + scale_fill_viridis_d(option="viridis") +
labs(title="Mean Hazard Index by Site Type (Hazard_Index>1)", x="Site Type", y="Mean Hazard Index", fill="Site Type", caption="Data source: MPART", subtitle="Numbers above bars indicate number of sites per type") +
theme_minimal() + theme(legend.position="right", axis.text.x=element_text(angle=45,hjust=1))
ggplotly(p, tooltip="text")
hazard_data <- merged_data |> filter(Hazard_Index>1, !is.na(type)) |> distinct(hex_id, type, analyte, analyte_value, Hazard_Index) |> filter(analyte %in% hazard_analytes)
hazard_summary_by_type <- hazard_data |> group_by(type, analyte) |> summarise(sum_analyte=sum(analyte_value, na.rm=TRUE), .groups="drop") |>
left_join(hazard_data |> group_by(type) |> summarise(total_hazard=sum(Hazard_Index, na.rm=TRUE), n_sites=n_distinct(hex_id), .groups="drop"), by="type") |>
pivot_wider(names_from=analyte, values_from=sum_analyte, values_fill=0) |> arrange(desc(total_hazard))
tbl_id1 <- "hazard_summary_table"
rt1 <- reactable(hazard_summary_by_type, elementId=tbl_id1, searchable=TRUE, filterable=TRUE, showPageSizeOptions=TRUE, defaultPageSize=10, highlight=TRUE, bordered=TRUE, striped=TRUE)
download_btn1 <- tags$button("Download CSV", onclick=sprintf("Reactable.downloadDataCSV('%s', 'hazard_summary_by_type.csv')", tbl_id1), style="margin-bottom:10px;")
browsable(tagList(download_btn1, rt1))
summary_table <- public_water_max_long |> distinct(system_type, hex_id, Hazard_Index) |>
group_by(system_type) |> summarise(total_hazard=sum(Hazard_Index, na.rm=TRUE), n_sites=n(), .groups="drop") |> arrange(desc(total_hazard))
tbl_id2 <- "system_type_hazard_table"
rt2 <- reactable(summary_table, elementId=tbl_id2, columns=list(system_type=colDef(name="System Type"), total_hazard=colDef(name="Total Hazard"), n_sites=colDef(name="Number of Sites")), searchable=TRUE, filterable=TRUE, showPageSizeOptions=TRUE, defaultPageSize=10, highlight=TRUE, bordered=TRUE, striped=TRUE)
download_btn2 <- tags$button("Download CSV", onclick=sprintf("Reactable.downloadDataCSV('%s','total_hazard_system_type.csv')", tbl_id2), style="margin-bottom:10px;")
browsable(tagList(download_btn2, rt2))
